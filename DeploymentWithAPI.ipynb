{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "### Predicting Customer Churn"}, {"metadata": {}, "cell_type": "markdown", "source": "### Environment Setup"}, {"metadata": {}, "cell_type": "code", "source": "#Uncomment and run once to install the wget package in your runtime environment\n!pip install wget", "execution_count": null, "outputs": []}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "#Uncomment and run once to install the package in your runtime environment\n!pip install pandas_profiling", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Uncomment and run once to install the package in your runtime environment\n!pip install sklearn-pandas", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Uncomment and run once to install the package in your runtime environment\n!pip install watson-machine-learning-client --upgrade\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import wget\nimport pandas as pd\nimport numpy as np\nimport pandas_profiling\nimport sklearn.pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, LabelBinarizer, OneHotEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score, accuracy_score, roc_curve, roc_auc_score\nfrom sklearn_pandas import DataFrameMapper\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import make_scorer\nimport json\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Step 1: Load data \n\n#### 1.1: Download the data files"}, {"metadata": {}, "cell_type": "code", "source": "# download data from GitHub repository\n\nurl_churn='https://raw.githubusercontent.com/SidneyPhoon/Data/master/churn.csv'\n\nurl_customer='https://raw.githubusercontent.com/SidneyPhoon/Data/master/customer-profile.csv'\n\n#remove existing files before downloading\n!rm -f churn.csv\n!rm -f customer-profile.csv\n\nchurnFilename=wget.download(url_churn)\ncustomerFilename=wget.download(url_customer)\n\n#list existing files\n!ls -l churn.csv\n!ls -l customer-profile.csv", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "customer_churn = pd.read_csv('churn.csv')\ncustomer = pd.read_csv('customer-profile.csv')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Step 2: Merge Files"}, {"metadata": {}, "cell_type": "code", "source": "data = pd.merge(customer, customer_churn, on='ID')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Step 3: Rename some columns\nThis step is to remove spaces from columns names, it's an example of data preparation that you may want to do before creating a model. "}, {"metadata": {}, "cell_type": "code", "source": "data.columns", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "data.rename(columns={'Est Income':'EstIncome', 'Car Owner':'CarOwner' }, inplace=True)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "data.head()", "execution_count": null, "outputs": []}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "data.shape", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Step 4: Data understanding"}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "data.describe()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#pandas_profiling.ProfileReport(data)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Step 5: Build the sklearn pipeline and the Random Forest model\n"}, {"metadata": {}, "cell_type": "code", "source": "# Define input data to the model\nX = data.drop(['ID','CHURN'], axis=1)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Define the target variable and encode with value between 0 and n_classes-1, that is from T/F to 1/0\nle = LabelEncoder()\ny = le.fit_transform(data['CHURN'])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "label_mapping=le.inverse_transform([0,1])\nprint('0: ', label_mapping[0])\nprint('1: ', label_mapping[1])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# split the data to training and testing set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=5)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### Use the DataFrameMapper class to declare transformations and variable imputations.\n\n* LabelBinarizer - Converts a categorical variable into a dummy variable (aka binary variable)\n* StandardScaler - Standardize features by removing the mean and scaling to unit variance, z = (x - u) / s\n\nSee docs: \n* https://github.com/scikit-learn-contrib/sklearn-pandas\n* https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler\n* https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html#sklearn.preprocessing.LabelBinarizer\n* https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html"}, {"metadata": {}, "cell_type": "code", "source": "\nmapper_good = DataFrameMapper([\n    (['Gender'], LabelBinarizer()),\n    (['Status'], LabelBinarizer()),\n    (['CarOwner'], LabelBinarizer()),\n    (['Paymethod'], LabelBinarizer()),\n    (['MembershipPlan'], LabelBinarizer()),\n    (['Children'],  StandardScaler()),\n    (['EstIncome'],  StandardScaler()),\n    (['Age'],  StandardScaler()),\n    (['AvgMonthlySpend'],  StandardScaler()),\n    (['CustomerSupportCalls'],  StandardScaler())], default=False)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Instantiate the Classifier\nrandom_forest = RandomForestClassifier(random_state=5)\n\n# Define the steps in the pipeline to sequentially apply a list of transforms and the estimator, i.e. RandomForestClassifier\nsteps = [('mapper', mapper_good),('RandonForestClassifier', random_forest)]\npipeline = sklearn.pipeline.Pipeline(steps)\n\n# train the model\nmodel=pipeline.fit( X_train, y_train )\n\nmodel", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Display Label Mapping to assist with interpretation of the model\nlabel_mapping=le.inverse_transform([0,1])\nprint('0: ', label_mapping[0])\nprint('1: ', label_mapping[1])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "### call pipeline.predict() on your X_test data to make a set of test predictions\ny_prediction = pipeline.predict( X_test )\n\n### test your predictions using sklearn.classification_report()\nreport = sklearn.metrics.classification_report( y_test, y_prediction )\n\n### and print the report\nprint(report)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "###  Step 6:  Tune the model to find the best model"}, {"metadata": {}, "cell_type": "code", "source": "# List keys to the model param to tune\n#model.get_params().keys()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "parameters = { 'RandonForestClassifier__max_depth': [5,8,10],\n               'RandonForestClassifier__n_estimators': [150,180,200]}", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "grid_obj = GridSearchCV(estimator=model, param_grid=parameters,  cv=3)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# TODO: Fit the grid search object to the training data and find the optimal parameters using fit()\ngrid_fit = grid_obj.fit(X_train,y_train)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Get the estimator\nbest_clf = grid_fit.best_estimator_", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "best_predictions = best_clf.predict(X_test)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "best_predictions_report = sklearn.metrics.classification_report( y_test, best_predictions )", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print('Results of best fitted model: \\n\\n',best_predictions_report)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print('Results of default model: \\n\\n',report)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "m_step=pipeline.named_steps['mapper']", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "m_step.transformed_names_", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "features = m_step.transformed_names_", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Get the features importance\nimportances = pipeline.named_steps['RandonForestClassifier'][1].feature_importances_\nindices = np.argsort(importances)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "plt.figure(1)\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b',align='center')\nplt.yticks(range(len(indices)), (np.array(features))[indices])\nplt.xlabel('Relative Importance')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Step 7: Save Model in the Project and WML Deployment Space\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Watson Machine Learning provides deployment spaces where the user can save, configure and deploy their models. We can also save the model in the project and then promote the model to the deployment space.  We will perform both operations in the code cells below.\n\nFirst, we will check if an existing deployment space is already associated with this project and set the associated deployment space as the default space.  If this project is not yet associated with a deployment space, we will create a deployment space.\n\nThe steps involved for saving and deploying the model into the deployment space are as follows:\n\n1. If a deployment space is already associated with this project, retrieve the SPACE_ID and space details, otherwise, create a new deployment space. \n2. Set the deployment space as the default space.\n3. Store the model pipeline in the deployment space. Enter the name for the model in the cell below. Specify a tag for the model in the cell below.\n4. Deploy the saved model. Enter the deployment name in the cell below. Specifu a tag for the deployment. Similarily, this tag will be used in the future to identify this deployment.\n5. Retrieve the scoring endpoint to score the model with a payload\n5. We will use the watson_machine_learning_client package to complete these steps. \n"}, {"metadata": {}, "cell_type": "code", "source": "from watson_machine_learning_client import WatsonMachineLearningAPIClient\nimport os\n\ntoken = os.environ['USER_ACCESS_TOKEN']\n\nwml_credentials = {\n   \"token\": token,\n   \"instance_id\" : \"wml_local\",\n   \"url\": os.environ['RUNTIME_ENV_APSX_URL'],\n   \"version\": \"2.5.0\"\n}\n\nclient = WatsonMachineLearningAPIClient(wml_credentials)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# specify values for the model_name, model_tag for the model to be saved\n\nmodel_name = 'customer_churn_model_1211'\nmodel_tag = 'customer_churn_model_tag_1211'\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Store the mode in the project"}, {"metadata": {}, "cell_type": "code", "source": "# get the Project ID and set the location to save the model to the project\nproject_id = os.environ['PROJECT_ID']\nclient.set.default_project(project_id)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "metadata = {\n    client.repository.ModelMetaNames.NAME: model_name,\n    client.repository.ModelMetaNames.TYPE: \"scikit-learn_0.20\",\n    client.repository.ModelMetaNames.RUNTIME_UID: \"scikit-learn_0.20-py3\",\n    client.repository.ModelMetaNames.TAGS: [{'value' : model_tag}]\n\n}\n\nstored_model_details = client.repository.store_model(pipeline,\n                                               meta_props=metadata,\n                                               training_data=X_train,\n                                               training_target=y_train)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Deployment Space\n\nUse an existing deployment space that is already associated with this project, or create a new deployment space if there is no associated deployment space"}, {"metadata": {}, "cell_type": "code", "source": "# get deployment space that is already associated with the project\n\nspace_id = os.getenv('SPACE_ID')\nif str(space_id)!='None':\n    space_name = client.spaces.get_details(space_id)['entity']['name']", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "space_id", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Obtain the UId of your space\n#def guid_from_space_name(client, space_name):\n#    instance_details = client.service_instance.get_details()\n#    space = client.spaces.get_details()\n#    return(next(item for item in space['resources'] if item['entity'][\"name\"] == space_name)['metadata']['guid'])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# if your project is indeed already associated with a space and the above code cell to display the space_id does not return anything, then uncomment the code below and\n# enter your deployment space name. I have see this problem before where a newly created project with a space associated with it does not have the \n# environment variable 'SPACE_ID'.\n\n\n# Enter the name of your deployment space here:\n#space_uid = guid_from_space_name(client, 'YOUR DEPLOYMENT SPACE')\n#print(\"Space UID = \" + space_uid)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### <font color='red'>Action required:</font> If this project is not already associated with a \"_Deployment Space_\", specify values for the space_name and space_tag in the code cell below"}, {"metadata": {}, "cell_type": "code", "source": "if str(space_id)=='None':\n    space_name = 'XXXXX '  # e.g deployment-space-sidneyp-sandbox \n    space_tag =  'XXXXX'   # e.g deployment-space-tag-sidneyp-sandbox\n    \n    # create the space and set it as default\n    space_meta_data = {\n            client.spaces.ConfigurationMetaNames.NAME : space_name,\n            client.spaces.ConfigurationMetaNames.TAGS : [{'value': space_tag}]\n    }\n\n    stored_space_details = client.spaces.store(space_meta_data)\n\n    space_uid = stored_space_details['metadata']['guid']\n\n    # set the newly created deployment space as the default\n    client.set.default_space(space_uid)\n    \n    \n\nelse:\n    # retrieve existing space details\n    stored_space_details = client.spaces.get_details(space_id)\n    space_uid = stored_space_details['metadata']['guid']\n    # set deployment space as the default\n    client.set.default_space(space_uid)\n    \n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Store the model in the deployment space"}, {"metadata": {}, "cell_type": "code", "source": "# run this line if you do not know the version of scikit-learn that was used to build the model\n!pip list | grep scikit-learn", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "metadata = {\n    client.repository.ModelMetaNames.NAME: model_name,\n    client.repository.ModelMetaNames.TYPE: \"scikit-learn_0.20\",\n    client.repository.ModelMetaNames.RUNTIME_UID: \"scikit-learn_0.20-py3\",\n    client.repository.ModelMetaNames.TAGS: [{'value' : model_tag}],\n    client.repository.ModelMetaNames.SPACE_UID: space_uid\n}\n\nstored_model_details = client.repository.store_model(pipeline,\n                                               meta_props=metadata,\n                                               training_data=X_train,\n                                               training_target=y_train)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "stored_model_details", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Create a deployment for the stored model"}, {"metadata": {}, "cell_type": "code", "source": "# specify values for the deployment_name, deployment_tag\n\ndeployment_name = 'customer_churn_model-deployment_1211'\ndeployment_tag = 'customer_churn_deployment_tag_1211'", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# deploy the model\nmeta_props = {\n    client.deployments.ConfigurationMetaNames.NAME: deployment_name,\n    client.deployments.ConfigurationMetaNames.TAGS : [{'value' : deployment_tag}],\n    client.deployments.ConfigurationMetaNames.ONLINE: {}\n}\n\n# deploy the model\n\nmodel_uid = stored_model_details[\"metadata\"][\"guid\"]\ndeployment_details = client.deployments.create( artifact_uid=model_uid, meta_props=meta_props)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Score the model"}, {"metadata": {}, "cell_type": "code", "source": "# retrieve the scoring endpoint\nscoring_endpoint = client.deployments.get_scoring_href(deployment_details)\n\nprint('Scoring Endpoint:   ',scoring_endpoint)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "scoring_deployment_id = client.deployments.get_uid(deployment_details)\nclient.deployments.get_details(scoring_deployment_id)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\n# payload_scoring = {\"input_data\": [{\"fields\": [\"Gender\", \"Status\", \"Children\", \"EstIncome\", \"CarOwner\", \"Age\", \"AvgMonthlySpend\", \"CustomerSupportCalls\", \"Paymethod\", \"MembershipPlan\"], \"values\": [[\"M\",\"S\",2.0,25000,\"Y\",25,10,1,\"CC\",1], [\"S\",\"S\",2.0,25000,\"Y\",25,10,1,\"CC\",1]]}]}\n\npayload_scoring = [{\"values\": [ [\"M\",\"S\",2.0,25000,\"Y\",25,10,1,\"CC\",1]]}]\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "payload_metadata = {client.deployments.ScoringMetaNames.INPUT_DATA: payload_scoring}\n# score\npredictions = client.deployments.score(scoring_deployment_id, payload_metadata)\npredictions", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# get the predicted value and reverse the label transformation\npredicted_value = predictions.get('predictions')[0].get('values')[0][0]\nle.inverse_transform([predicted_value])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### <font color='red'>Action required:</font> \nTo see your deployed models, go to your project **Settings** -> **Associated deployment space**.  If this project is not yet associated with a deployment space, associate it with the newly created deployment space.  Clicked into the associated deployment space to see the deployed model."}, {"metadata": {}, "cell_type": "markdown", "source": "#### Write test data into csv file for batch scoring"}, {"metadata": {}, "cell_type": "code", "source": "# Write the test data a .csv so that we can later use it for batch scoring\nX_test.to_csv('/project_data/data_asset/new_customers.csv', sep=',', index=False)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "**Author:**  Sidney Phoon <br/>\n**Date:**  Dec 5th, 2019"}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.8", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}